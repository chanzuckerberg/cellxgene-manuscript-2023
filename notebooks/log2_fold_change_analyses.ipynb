{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29b3d441-655b-445c-9ec1-77167b53b6fa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Batch Effects Present in Average Gene Expression Values\n",
    "Exploring the distribution of absolute log fold change values between pairwise average gene expression vectors stratified by covariates.<br>\n",
    "Note that throughout the notebook, we use *'rankit'* and *'quantile normalization'* interchangeably. A brief overview can be found <a href = 'https://en.wikipedia.org/wiki/Quantile_normalization'>here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "662325e6-9f4b-478e-9f1e-ff3a408af436",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "import pingouin as pg\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de396b5c-8060-47ae-8a0f-b471cacaa7ad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Marker + Housekeeping Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f7dd2f6-7786-4c44-ac27-771aa914b5e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "NUM_MIN_EXPRESSED_GENES_PER_CELL = 500\n",
    "NUM_MIN_ULTRA_LOW_EXPRESSED_GENES = 2\n",
    "CENSUS_VERSION = \"2023-10-18\"\n",
    "ASSAYS = ['sci-RNA-seq', 'Seq-Well', 'Drop-seq', 'CEL-seq2', \"10x 3\\\\' v1\", \"10x 5\\\\' v1\", \"10x 3\\\\' v2\", \"10x 5\\\\' v2\", \"10x 3\\\\' v3\", \"10x 3\\\\' transcription profiling\", \"10x 5\\\\' transcription profiling\", \"10x technology\"]\n",
    "HOUSEKEEPING_GENES = ['MALAT1', 'ACTB', 'GAPDH', 'UBC', 'SDHA', 'YWHAZ', 'PGK1', 'PPIA', 'RPL13A', 'RPLP0', 'B2M']\n",
    "NUM_MARKER_GENES = 5\n",
    "\n",
    "contents_cell_types = open('../data/data_tidy/overlapping_categories.json').read()\n",
    "contents_marker_genes = open('../data/data_raw/hubmap_marker_genes.json').read()\n",
    "tissue2cell_types = json.loads(contents_cell_types)\n",
    "marker_genes = json.loads(contents_marker_genes)\n",
    "\n",
    "cell_type_mapping = {\n",
    "    'CL:4028006' : 'alveolar type 2 fibroblast cell',\n",
    "    'CL:0000525' : 'syncytiotrophoblast cell',\n",
    "    'CL:0000786' : 'plasma cell',\n",
    "    'CL:0000895' : 'naive thymus-derived CD4-positive, alpha-beta T cell',\n",
    "    'CL:0000909' : 'CD8-positive, alpha-beta memory T cell',\n",
    "    'CL:0000071' : 'blood vessel endothelial cell',\n",
    "    'CL:0000899' : 'T-helper 17 cell',\n",
    "    'CL:0000084' : 'T cell',\n",
    "    'CL:1001106' : 'kidney loop of Henle thick ascending limb epithelial cell'\n",
    "}\n",
    "mapping2cell_type = {v:k for k, v in cell_type_mapping.items()}\n",
    "\n",
    "def get_marker_genes(tissue, cell_type):\n",
    "    return [entry['symbol'] for entry in marker_genes[mapping2cell_type[cell_type]] if entry['tissue'] == tissue]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2552e903-c93e-4cf8-be3c-e6b15b614d3d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Rankit Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3d3ac17-bb29-4d76-a6b4-c1ebd2062f78",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import cellxgene_census\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from scipy import stats\n",
    "import scipy \n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "@nb.jit\n",
    "def quantiles(max_rank: int, ranks: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    :returns an array of n floats equally spaced from 0 to 1\n",
    "    \"\"\"\n",
    "    return np.array([np.round((i - 0.5) / max_rank, 5) for i in ranks])\n",
    "\n",
    "\n",
    "def rankit(Xraw: scipy.sparse.spmatrix, offset: float = 3.0) -> scipy.sparse.csr_matrix:\n",
    "    \"\"\"\n",
    "    Row-wise normalizes values of a matrix using the rankit method. The target distribution is a normal distribution\n",
    "    with variance of 1 and mean as set in `offset`\n",
    "    https://en.wikipedia.org/wiki/Rankit\n",
    "    In statistics, rankits of a set of data are the expected values of the order statistics of\n",
    "    a sample from the standard normal distribution the same size as the data\n",
    "    Caveat: equal values are ranked in undefined order.\n",
    "    param Xraw: query matrix to be normalized\n",
    "    param offset: mean for the resulting row-wise values that will follow a normal distribution with variance 1. This\n",
    "    helps to shift values to a positive scale.\n",
    "    :returns row-wise normalized matrix using rankit\n",
    "    \"\"\"\n",
    "    X = Xraw.tocsr(copy=True)  # get Compressed Sparse Row format of raw expression values matrix\n",
    "    indptr = X.indptr  # get row count\n",
    "    warning_raised = False\n",
    "    for row in range(0, indptr.shape[0] - 1):\n",
    "        data = X.data[indptr[row] : indptr[row + 1]]\n",
    "        if len(data) > 0:\n",
    "            # Assign ranks to data, assigning the same value to ties\n",
    "            ranks = stats.rankdata(data, method=\"dense\")\n",
    "\n",
    "            max_rank = max(ranks)\n",
    "            prob_level = quantiles(max_rank, ranks)\n",
    "\n",
    "            normal_quantiles = stats.norm.ppf(prob_level, loc=offset)\n",
    "            X.data[indptr[row] : indptr[row + 1]] = normal_quantiles\n",
    "        elif not warning_raised:\n",
    "            print(\"This dataset has at least one row of all zero expressions\")\n",
    "            warning_raised = True\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3c06c92-40c4-489d-a274-795fda163f5a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb06e777-0470-45f1-958d-66db9ad0677a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_census_query(cell_types, tissues, assays):\n",
    "    \"\"\"\n",
    "    Returns a value filter query for the census to retrieve data for \n",
    "    a given array of cell types, tissues and assays\n",
    "\n",
    "    :param cell_types: the cell_types to retrieve from the census\n",
    "    :param tissues: the tissues the cell_types are found in\n",
    "    :param assays: the assays corresponding to the cell_types and tissues\n",
    "\n",
    "    :return: the value_filter query\n",
    "    \"\"\"\n",
    "    value_filter = \"is_primary_data == True and cell_type in [\" \n",
    "    for cell_type in cell_types:\n",
    "        value_filter += \"'\" + cell_type.replace(\"'\", \"\\\\'\") + \"', \"\n",
    "    value_filter = value_filter[:-2] + \"] and tissue_general in [\"\n",
    "    for tissue in tissues:\n",
    "        value_filter += \"'\" + tissue + \"', \"\n",
    "    value_filter = value_filter[:-2] + \"] and assay in [\"\n",
    "    for assay in assays:\n",
    "        value_filter += \"'\" + assay + \"', \"\n",
    "    value_filter = value_filter[:-2] + \"]\"\n",
    "    return value_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f684290-66cf-426e-8a40-23276def4a4b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_census_metadata(cell_types, tissues, assays, census):\n",
    "    \"\"\"\n",
    "    Queries the census to retrieve metadata for a given array of cell_types, tissues and assays\n",
    "\n",
    "    :param cell_types: the cell_types to retrieve metadata for\n",
    "    :param tissues: the tissues the cell_types are found in\n",
    "    :param assays: the assays corresponding to the cell_types and tissues\n",
    "\n",
    "    :return:\n",
    "        metadata: metadata retrieved from the census \n",
    "        census_query: the query used to retrieve the metadata from cellxgene_census\n",
    "        genes: the set of corresponding genes from the census\n",
    "    \"\"\"\n",
    "    census_query = get_census_query(cell_types, tissues, assays)\n",
    "    \n",
    "    # Reads SOMADataFrame as a slice\n",
    "    metadata = census[\"census_data\"][\"homo_sapiens\"].obs.read(\n",
    "        value_filter = census_query,\n",
    "        column_names = [\"soma_joinid\", \"assay\", \"dataset_id\", \"cell_type\", \"tissue\", \"tissue_general\", \"suspension_type\", \"disease\", \"donor_id\", \"raw_sum\"]\n",
    "    )\n",
    "\n",
    "    genes = census[\"census_data\"][\"homo_sapiens\"].ms[\"RNA\"].var.read().concat().to_pandas()\n",
    "        \n",
    "    # Concatenates results to pyarrow.Table\n",
    "    metadata = metadata.concat()\n",
    "    \n",
    "    # Converts to pandas.DataFrame\n",
    "    metadata = metadata.to_pandas()\n",
    "    # metadata['cell_type'] = metadata['cell_type'].apply(lambda x: cell_type2parents[x])\n",
    "        \n",
    "    print('There are', len(metadata), 'observations')\n",
    "    return metadata, census_query, genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4a94fee-7080-4781-8a52-c4dffa06e66c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Get X iteratively and perform normalizations\n",
    "**1. Pre-processing**\n",
    "- *Remove cells with <500 expressed genes*\n",
    "\n",
    "**2. Normalizations**\n",
    "1. Rankit\n",
    "2. log CPM\n",
    "\n",
    "**3. Post-processing** <br>\n",
    "- *Removal of Noisy Ultra-low Expression Values* <br>\n",
    "After applying normalization, any gene/cell combination that had counts less or equal than 2 are set to missing data. This allows for removal of noise due to ultra-lowly expressed genes and provides a cleaner visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9d38723-8254-42a3-8843-7d7226e93e98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from cellxgene_census.experimental.util import X_sparse_iter\n",
    "import tiledbsoma as soma\n",
    "\n",
    "def get_raw_count_data_and_normalize(cell_type, tissue, assays):\n",
    "    \"\"\"\n",
    "    Retrieves raw counts data from the census for a given cell_type, tissue and set of assays \n",
    "    and performs quantile normalization and log (CPM) normalizations. Data is retrieved in batches.\n",
    "\n",
    "    :param cell_type: cell_type to get data for\n",
    "    :param tissue: corresponding tissue for the cell_type\n",
    "    :param assays: assays corresponding to the cell_type and tissue\n",
    "\n",
    "    :return:\n",
    "        all_X_raw_counts: raw counts data\n",
    "        all_X_rankit: quantile normalized data\n",
    "        all_X_log_cpm: log (CPM) normalized data\n",
    "        genes: the set of corresponding genes from the census\n",
    "    \"\"\"\n",
    "    with cellxgene_census.open_soma(census_version=CENSUS_VERSION) as census:\n",
    "        tissues = [tissue]\n",
    "        cell_types = [cell_type]\n",
    "\n",
    "        metadata, value_filter, genes = get_census_metadata(cell_types, tissues, assays, census)\n",
    "        exp = census[\"census_data\"][\"homo_sapiens\"]\n",
    "        query = exp.axis_query(\n",
    "        measurement_name = \"RNA\",\n",
    "        obs_query = soma.AxisQuery(\n",
    "            value_filter = value_filter\n",
    "        ))\n",
    "        all_obs_soma_joinids = []\n",
    "        all_var_soma_joinids = []\n",
    "        all_X_raw_counts = None\n",
    "        all_X_rankit = None\n",
    "        all_X_log_cpm = None\n",
    "\n",
    "        i = 0\n",
    "        for (obs_soma_joinids, var_soma_joinids), X_chunk in X_sparse_iter(query, X_name=\"raw\", stride=10000):\n",
    "            print('Parsing chunk Batch:', i)\n",
    "\n",
    "            # Remove cells with < 500 expressed genes\n",
    "            n_obs = X_chunk.shape[0]\n",
    "            non_zero = [X_chunk[i,:].count_nonzero() for i in range(n_obs)]\n",
    "            mask = [i >= NUM_MIN_EXPRESSED_GENES_PER_CELL for i in non_zero]\n",
    "            obs_soma_joinids = obs_soma_joinids[mask]\n",
    "\n",
    "            all_obs_soma_joinids.extend(obs_soma_joinids)\n",
    "            all_var_soma_joinids.extend(var_soma_joinids)\n",
    "\n",
    "            X_chunk = X_chunk[mask, :]\n",
    "\n",
    "            print('\\tCompute rankit values Batch:', i)\n",
    "            # Compute rankit values\n",
    "            X_rankit = rankit(X_chunk)\n",
    "\n",
    "            # Removal of ultra-low expressed genes\n",
    "            nonzero_mask = X_chunk.nonzero()\n",
    "            X_chunk_nonzero = X_chunk[nonzero_mask]\n",
    "            lowly_expressed_mask = np.array(X_chunk_nonzero <= NUM_MIN_ULTRA_LOW_EXPRESSED_GENES)[0]\n",
    "\n",
    "            nonzero_rows_indices = nonzero_mask[0][lowly_expressed_mask]\n",
    "            nonzero_cols_indices = nonzero_mask[1][lowly_expressed_mask]\n",
    "\n",
    "            X_rankit[nonzero_rows_indices, nonzero_cols_indices] = 0\n",
    "            X_rankit.eliminate_zeros()\n",
    "\n",
    "            X_chunk[nonzero_rows_indices, nonzero_cols_indices] = 0\n",
    "            X_chunk.eliminate_zeros()\n",
    "\n",
    "            # Compute log CPM values\n",
    "            print('\\tCompute log CPM values Batch:', i)\n",
    "            library_sizes = np.array(metadata[metadata['soma_joinid'].isin(obs_soma_joinids)]['raw_sum']).reshape(-1, 1)\n",
    "            X_cpm = X_chunk / library_sizes * 1e6\n",
    "            X_log_cpm = scipy.sparse.csr_matrix(np.log(X_cpm + 1))\n",
    "\n",
    "            X_log_cpm[nonzero_rows_indices, nonzero_cols_indices] = 0\n",
    "            X_log_cpm.eliminate_zeros()\n",
    "\n",
    "            if i == 0:\n",
    "                all_X_raw_counts = X_chunk\n",
    "                all_X_rankit = X_rankit    \n",
    "                all_X_log_cpm = X_log_cpm   \n",
    "            else:\n",
    "                all_X_raw_counts = scipy.sparse.vstack((all_X_raw_counts, X_chunk))\n",
    "                all_X_rankit = scipy.sparse.vstack((all_X_rankit, X_rankit))\n",
    "                all_X_log_cpm = scipy.sparse.vstack((all_X_log_cpm, X_log_cpm))\n",
    "            i += 1\n",
    "            # X_chunk is a scipy.csr_matrix of csc_matrix\n",
    "            # For each X_chunk[i, j], the associated soma_joinid is\n",
    "            # obs_soma_joinids[i] and var_soma_joinids[j]\n",
    "    metadata = metadata[metadata['soma_joinid'].isin(all_obs_soma_joinids)]\n",
    "    metadata['m_idx'] = [i for i in range(len(metadata))]\n",
    "\n",
    "    obs_soma_joinid2idx = {x : i for i, x in enumerate(all_obs_soma_joinids)}\n",
    "    obs_idx2soma_joinid = {v:k for k, v in obs_soma_joinid2idx.items()}\n",
    "\n",
    "    var_idx2soma_joinid = {i : x for i, x in enumerate(all_var_soma_joinids)}\n",
    "    var_soma_joinid2idx = {v:k for k, v in var_idx2soma_joinid.items()}\n",
    "    return all_X_raw_counts, all_X_rankit, all_X_log_cpm, metadata, genes, obs_soma_joinid2idx, var_idx2soma_joinid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c3b12e1-7585-46a4-a2f5-e8b9bbcccb54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_average_ge(X):\n",
    "    \"\"\"\n",
    "    Get average gene expression values for raw or normalized matrix X\n",
    "\n",
    "    :param X: raw or normalized (quantile, log CPM) matrix of gene expression values\n",
    "\n",
    "    :return: array containing average gene expression values, where each entry corresponds to the average for a specicic gene\n",
    "    \"\"\"\n",
    "    covariate_gene_expression_sums = X.sum(axis = 0).tolist()[0]\n",
    "    num_genes = X.shape[1]\n",
    "    non_zero_cols, non_zero_counts = np.unique(X.indices, return_counts=True)\n",
    "    averages = np.zeros(num_genes)\n",
    "    for non_zero_col, non_zero_counts in zip(non_zero_cols, non_zero_counts):\n",
    "        averages[non_zero_col] = covariate_gene_expression_sums[non_zero_col] / non_zero_counts\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39ac9c7f-7c7a-4d0e-ae2e-bd1d6b1101c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "def get_covariate_and_log2_fold_df(metadata, genes, X_raw, X_rankit, X_log_cpm, obs_soma_joinid2idx, covariate, genes_of_interest):\n",
    "    \"\"\"\n",
    "    Computes average gene expression values per covariate and log2fold changes between pairwise average gene expression vectors\n",
    "\n",
    "    :param metadata: dataframe containing metadata information about the cell type considered\n",
    "    :param genes: the set of corresponding genes from the census\n",
    "    :param X_raw: raw counts data\n",
    "    :param X_rankit: quantile normalized data\n",
    "    :param X_log_cpm: log (CPM) normalized data\n",
    "    :param obs_soma_joinid2idx: mapping from obs_soma_join_id to idx in the X matrices\n",
    "    :param covariate: covariate to consider (dataset_id or assay)\n",
    "    :param genes_of_interest: genes to subset from the census\n",
    "\n",
    "    :returns:\n",
    "        covariate_raw_df: average gene expression values per covariate for raw counts\n",
    "        covariate_rankit_df: average gene expression values per covariate for quantile normalized (rankit) data\n",
    "        covariate_log_cpm_df: average gene expression values per covariate for log CPM normalized data\n",
    "        covariate_df: average gene expression values per covariate aggregated over raw, quantile normalized and log CPM data\n",
    "        covariate_log2_fc: dataframe containing pairwise log2 fold changes\n",
    "    \"\"\"\n",
    "    covariates_grouped = metadata.groupby(covariate).aggregate(list)\n",
    "    all_covariate_indices = covariates_grouped['soma_joinid'].to_list()\n",
    "    num_covariates = len(all_covariate_indices)\n",
    "    gene_expression_averages_raw = []\n",
    "    gene_expression_averages_rankit = []\n",
    "    gene_expression_averages_log_cpm = []\n",
    "\n",
    "    gene_expression_raw_by_covariate = []\n",
    "    gene_expression_rankit_by_covariate = []\n",
    "    gene_expression_log_cpm_by_covariate = []\n",
    "    print('There are', num_covariates, covariate)\n",
    "\n",
    "    all_indices = []\n",
    "    for covariate_idx in range(num_covariates):\n",
    "        soma_join_ids = all_covariate_indices[covariate_idx]\n",
    "        covariate_indices = [obs_soma_joinid2idx[x] for x in soma_join_ids]\n",
    "        all_indices.extend(covariate_indices)\n",
    "\n",
    "        covariate_gene_expression_avg_raw = get_average_ge(X_raw[covariate_indices])\n",
    "        covariate_gene_expression_avg_rankit = get_average_ge(X_rankit[covariate_indices])\n",
    "        covariate_gene_expression_avg_log_cpm = get_average_ge(X_log_cpm[covariate_indices])\n",
    "\n",
    "        gene_expression_averages_raw.append(covariate_gene_expression_avg_raw)\n",
    "        gene_expression_averages_rankit.append(covariate_gene_expression_avg_rankit)\n",
    "        gene_expression_averages_log_cpm.append(covariate_gene_expression_avg_log_cpm)\n",
    "\n",
    "        covariate_gene_expression_raw = X_raw[covariate_indices].toarray()\n",
    "        covariate_gene_expression_rankit = X_rankit[covariate_indices].toarray()\n",
    "        covariate_gene_expression_log_cpm = X_log_cpm[covariate_indices].toarray()\n",
    "\n",
    "        gene_expression_raw_by_covariate.append(covariate_gene_expression_raw)\n",
    "        gene_expression_rankit_by_covariate.append(covariate_gene_expression_rankit)\n",
    "        gene_expression_log_cpm_by_covariate.append(covariate_gene_expression_log_cpm)\n",
    "\n",
    "    covariates_list = covariates_grouped.index.to_list()\n",
    "    covariate_df = pd.DataFrame(columns = ['cell_type_raw_count_avg', 'cell_type_rankit_avg', 'cell_type_log_cpm_avg'] + [x + '_raw_count_avg' for i, x in enumerate(covariates_list)] + [x +  '_rankit_avg' for i, x in enumerate(covariates_list)] + [x +  '_log_cpm_avg' for i, x in enumerate(covariates_list)])\n",
    "\n",
    "    covariate_df['cell_type_raw_count_avg'] = get_average_ge(X_raw[all_indices])\n",
    "    covariate_df['cell_type_rankit_avg'] = get_average_ge(X_rankit[all_indices])\n",
    "    covariate_df['cell_type_log_cpm_avg'] = get_average_ge(X_log_cpm[all_indices])\n",
    "\n",
    "    for cov_raw, cov_rankit, cov_log_cpm, cov in zip(gene_expression_averages_raw, gene_expression_averages_rankit, gene_expression_averages_log_cpm, covariates_list):\n",
    "        covariate_df[cov + '_raw_count_avg'] = cov_raw\n",
    "        covariate_df[cov + '_rankit_avg'] = cov_rankit\n",
    "        covariate_df[cov + '_log_cpm_avg'] = cov_log_cpm\n",
    "\n",
    "    covariate_df.index = genes_of_interest\n",
    "\n",
    "    covariate_raw_df = covariate_df[[x for x in covariate_df.columns.to_list() if 'raw_count' in x]]\n",
    "    covariate_rankit_df = covariate_df[[x for x in covariate_df.columns.to_list() if 'rankit' in x]]\n",
    "    covariate_log_cpm_df = covariate_df[[x for x in covariate_df.columns.to_list() if 'log_cpm' in x]]\n",
    "\n",
    "    covariate_raw_df_log2_fc, num_pairs, cov_raw_ttest = log2_fold_change(covariate_raw_df, gene_expression_raw_by_covariate, 'raw_counts')\n",
    "    covariate_rankit_df_log2_fc, _, cov_rankit_ttest = log2_fold_change(covariate_rankit_df, gene_expression_rankit_by_covariate, 'rankit')\n",
    "    covariate_log_cpm_df_log2_fc, _, cov_log_cpm_ttest = log2_fold_change(covariate_log_cpm_df, gene_expression_log_cpm_by_covariate, 'log CPM')\n",
    "\n",
    "    covariates_grouped = metadata.groupby(covariate).aggregate(list)\n",
    "    all_covariate_indices = covariates_grouped['soma_joinid'].to_list()\n",
    "    num_genes = len(genes)\n",
    "\n",
    "    covariate_raw_df_log2_fc['method'] = 'raw counts'\n",
    "    covariate_rankit_df_log2_fc['method'] = 'rankit'\n",
    "    covariate_log_cpm_df_log2_fc['method'] = 'log CPM'\n",
    "\n",
    "    covariate_raw_df_log2_fc_new = get_log2_fold_stats_df(covariate_raw_df_log2_fc, cov_raw_ttest, 'raw counts')\n",
    "    covariate_rankit_df_log2_fc_new = get_log2_fold_stats_df(covariate_rankit_df_log2_fc, cov_rankit_ttest, 'rankit')\n",
    "    covariate_log_cpm_df_log2_fc_new = get_log2_fold_stats_df(covariate_log_cpm_df_log2_fc, cov_log_cpm_ttest, 'log CPM')\n",
    "\n",
    "    covariate_log2_fc = pd.concat([covariate_raw_df_log2_fc_new, covariate_rankit_df_log2_fc_new, covariate_log_cpm_df_log2_fc_new], axis = 0)\n",
    "    covariate_log2_fc.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    covariate_log2_fc.dropna(inplace=True)\n",
    "    covariate_log2_fc['covariate'] = covariate\n",
    "\n",
    "    return covariate_raw_df, covariate_rankit_df, covariate_log_cpm_df, covariate_df, covariate_log2_fc, cov_raw_ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9576b8b2-9abb-4d8d-9f28-5e5a08ef8ab8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def log2_fold_change(covariate_df, gene_expressions, method):\n",
    "    \"\"\"\n",
    "    Computes log2_fold_changes between pairs of vectors from covariate_df\n",
    "\n",
    "    :param covariate_df: dataframe containing vectors to compute log2_fold_changes for\n",
    "    :param gene_expressions: vector containing gene_expression values (raw or normalized)\n",
    "    :param method: method used (raw counts, rankit, or log CPM)\n",
    "\n",
    "    :return:\n",
    "        new_cov_df: dataframe containing log2_fold changes\n",
    "        num_pairs: number of pairs considered\n",
    "        new_ttest_df: dataframe containing ttest p-values for the pairs considered\n",
    "    \"\"\"\n",
    "    columns = covariate_df.columns[1:]\n",
    "    num_cols = len(columns)\n",
    "    num_pairs = num_cols * (num_cols - 1) / 2\n",
    "    pair2log_fold = {}\n",
    "    pair2mean = {}\n",
    "    pair2ttest = {}\n",
    "    col_names = []\n",
    "    means = []\n",
    "    for i, c1 in enumerate(columns):\n",
    "        for j, c2 in enumerate(columns):\n",
    "            col_name = 'P_' + str(i) + '_' + str(j)\n",
    "            ttest = stats.ttest_ind(gene_expressions[i], gene_expressions[j], equal_var=False)\n",
    "            statistic = ttest.statistic\n",
    "            pvalues = ttest.pvalue\n",
    "            if j > i:\n",
    "                pair2log_fold[col_name] = np.log2(covariate_df[c1]) - np.log2(covariate_df[c2])\n",
    "                pair2mean[col_name] = covariate_df[c1]\n",
    "                col_names.append(col_name)\n",
    "                pair2ttest[col_name] = (statistic, pvalues)\n",
    "    new_covariate_df = pd.DataFrame(columns = col_names)\n",
    "    ttest_df = pd.DataFrame()\n",
    "    for col in col_names:\n",
    "        new_covariate_df[col] = pair2log_fold[col]\n",
    "        new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
    "        ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
    "        ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
    "    new_cov_df = new_covariate_df.T\n",
    "    new_ttest_df = ttest_df.T\n",
    "    new_ttest_df.columns = new_cov_df.columns\n",
    "    new_ttest_df['method'] = method\n",
    "    new_cov_df['method'] = method\n",
    "    return new_cov_df, num_pairs, new_ttest_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a289eb81-647e-445d-830b-0af1af339af8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Log Fold Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8505b944-abd3-4679-97db-9daf253a7565",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_log2_fold_stats_df(method_df, ttest_df, method):\n",
    "    \"\"\"\n",
    "    Returns a dataframe containing log2 fold changes and statistics, such as mean, ttest statistic and p_value for each \n",
    "    pair of gene expression vectors\n",
    "\n",
    "    :param method_df: dataframe containing log2 fold changes for the given method\n",
    "    :param ttest_df: dataframe containing ttest statistics for the given method\n",
    "    :param method: one of raw counts, rankit of log (CPM)\n",
    "\n",
    "    :returns: dataframe containing pairwise log2 fold change, mean, gene_name, ttest statistic, ttest p_value and method\n",
    "    \"\"\"\n",
    "    columns = method_df.columns[:-1]\n",
    "    rows_mean = [x for x in list(method_df.index) if 'avg' in x]\n",
    "    rows_dist = [x for x in list(method_df.index) if 'avg' not in x]\n",
    "\n",
    "    rows_ttest = [x for x in list(ttest_df.index) if 'statistic' in x]\n",
    "    rows_p_value = [x for x in list(ttest_df.index) if 'p_value' in x]\n",
    "\n",
    "    pairwise_log_fold_changes = []\n",
    "    ttest_stats = []\n",
    "    ttest_pvalues = []\n",
    "    gene_names = []\n",
    "    methods = []\n",
    "    means = []\n",
    "    for col in columns:\n",
    "        gene_expression_col = method_df.loc[rows_dist, col].to_list()\n",
    "        mean_col = method_df.loc[rows_mean, col].to_list()\n",
    "        ttest_stats_col = ttest_df.loc[rows_ttest, col].to_list()\n",
    "        ttest_pval_col = ttest_df.loc[rows_p_value, col].to_list()\n",
    "\n",
    "        pairwise_log_fold_changes.extend(gene_expression_col)\n",
    "        means.extend(mean_col)\n",
    "        ttest_stats.extend(ttest_stats_col)\n",
    "        ttest_pvalues.extend(ttest_pval_col)\n",
    "        gene_names.extend([col] * len(gene_expression_col))\n",
    "        methods.extend([method] * len(gene_expression_col))\n",
    "    df = pd.DataFrame({'pairwise log2 fold change' : pairwise_log_fold_changes, 'mean' : means, 'gene_name' : gene_names, 'ttest statistic' : ttest_stats, 'ttest p_value' : ttest_pvalues, 'method' : methods})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "831659bd-cbb2-4473-9149-4246f24890a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def transform_covariate_df(covariate_df, method_type, covariate, cell, tissue):\n",
    "    \"\"\"\n",
    "    Transposes and augments a given dataframe by addint method, covariate and cell_type as new fields\n",
    "\n",
    "    :param covariate_df: the df to transform\n",
    "    :param method_type: one of raw_counts, rankit or log (CPM)\n",
    "    :param covariate: type of covariate - usually dataset_id or assay\n",
    "    :param cell: cell_type for the corresponding covariate_df\n",
    "    :param tissue: tissue for the corresponding covariate_df\n",
    "    \"\"\"\n",
    "    covariate_df = covariate_df.T\n",
    "    covariate_df['method'] = method_type\n",
    "    covariate_df['covariate'] = covariate\n",
    "    covariate_df['cell_type'] = cell + \", \" + tissue\n",
    "    return covariate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0010a2fb-6cb6-4ea9-b955-8530f8da38af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Choose cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ea98a29-f3d0-40fe-94b8-92c889a9d4e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# code used to generate cell types as leaf nodes in the ontology\n",
    "cell_types_set = True\n",
    "if not cell_types_set:\n",
    "    with cellxgene_census.open_soma(census_version=CENSUS_VERSION) as census:\n",
    "        human = census[\"census_data\"][\"homo_sapiens\"]\n",
    "        obs_df = human.obs.read(column_names=[\"cell_type_ontology_term_id\", \"cell_type\", \"tissue\", \"tissue_general\"]).concat().to_pandas()\n",
    "        obs_df.groupby(by=[\"cell_type_ontology_term_id\", \"cell_type\"], as_index=False, observed=True).size()\n",
    "\n",
    "        obs_df_unique = obs_df[['cell_type', 'cell_type_ontology_term_id']].drop_duplicates()\n",
    "        cell_type_id2cell_type = {}\n",
    "        for idx, row in obs_df_unique.iterrows():\n",
    "            cell_type_id2cell_type[row['cell_type_ontology_term_id']] = row['cell_type']\n",
    "\n",
    "        tissues_general = obs_df['tissue_general'].unique()\n",
    "\n",
    "        # choose 5 random tissues that have cell types that are leaves in the ontology\n",
    "        tissue2cell_types_leaves = json.loads(open('../data/terminal_cell_types.json').read())\n",
    "        tissues_general_leaves = np.random.choice([x for x in tissue2cell_types_leaves.keys() if x in tissues_general], 5, replace = False)\n",
    "\n",
    "        #  for each tissue, select 2 cell types that are leaves in the ontology at random\n",
    "        cell_types = []\n",
    "        for t in tissues_general_leaves:\n",
    "            cell_type_leaves = tissue2cell_types_leaves[t]\n",
    "            if len(cell_type_leaves) > 2:\n",
    "                cell_type_leaves = np.random.choice(cell_type_leaves, 2, replace = False)\n",
    "            for c in cell_type_leaves:\n",
    "                cell_types.append((cell_type_id2cell_type[c], t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46585b22-55de-4045-a42e-7cf992d0536e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Generate log2 fold figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14e8fcb7-c110-4732-86d1-606ae1a8512b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def sample_obs_per_cell_type(cell_types, log2_fold_df, num_obs_per_cell_type = 30000):\n",
    "    \"\"\"\n",
    "    Samples the log2_fold_df dataframe to contain a maximum of num_obs_per_cell_type observations\n",
    "    per cell_type\n",
    "\n",
    "    :param cell_types: the cell_types in log2_fold_df\n",
    "    :param log2_fold_df: datafrane containing log2_fold pairwise changes\n",
    "    :param num_obs_per_cell_type: number of max obs to sample to per cell_type\n",
    "\n",
    "    :return: sampled log2_fold_df where each cell_type has a maximum of num_obs_per_cell_type observations\n",
    "    \"\"\"\n",
    "    all_indices = []\n",
    "    for ct in cell_types:\n",
    "        cell_type_indices = log2_fold_df[log2_fold_df['cell_type'] == ct].index\n",
    "        indices = np.random.choice(cell_type_indices, min(num_obs_per_cell_type, len(cell_type_indices)), replace = False)\n",
    "        all_indices.extend(indices)\n",
    "    log2_fold_df = log2_fold_df.iloc[all_indices]\n",
    "    return log2_fold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37e06aa3-7c8c-46d9-9969-5d5698278ca0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_pairwise_stratified_log2_fold_changes(cell_types, covariates = ['dataset_id', 'assay'], all_genes = False):\n",
    "    \"\"\"\n",
    "    Retrieve pairwise log2fold changes for a given set of [(cell_type, tissue)] pairs stratified by covariates\n",
    "    Computes values for raw counts, quantile normalization and log (CPM)\n",
    "\n",
    "    :param cell_types: array of [(cell_type, tissue)] pairs\n",
    "    :param covariates: covariates to consider\n",
    "    :param all_genes: True if to consider the entire gene expression vector; False if to consider only the marker genes\n",
    "\n",
    "    :return: dataframe containing the pairwise log2fold changes for a given set of [(cell_type, tissue)] pairs stratified by covariates\n",
    "    \"\"\"\n",
    "    all_dfs = []\n",
    "    all_covariate_dfs_raw = []\n",
    "    all_covariate_dfs_rankit = []\n",
    "    all_covariate_dfs_log_cpm = []\n",
    "    genes_set = False\n",
    "        \n",
    "\n",
    "    for cell_type, tissue in cell_types:\n",
    "\n",
    "        X_raw_counts, X_rankit, X_log_cpm, metadata, genes, obs_soma_joinid2idx, var_idx2soma_joinid = get_raw_count_data_and_normalize(cell_type, tissue, ASSAYS)\n",
    "        if len(metadata) == 0:\n",
    "            continue\n",
    "        if not genes_set:\n",
    "            marker_genes = genes['feature_name'].to_list()\n",
    "            genes_set = True\n",
    "        var_soma_joinid2idx = {i : x for i, x in var_idx2soma_joinid.items()}\n",
    "\n",
    "        if not all_genes:\n",
    "            marker_genes = get_marker_genes(tissue, cell_type) \n",
    "        marker_genes_indices =  list([var_soma_joinid2idx[genes[genes['feature_name'] == x]['soma_joinid'].values[0]] for x in marker_genes])\n",
    "        \n",
    "        for genes_indices, genes_type, genes_of_interest in zip([marker_genes_indices], ['gene'], [marker_genes]):\n",
    "            for covariate in covariates:\n",
    "                covariate_raw_df, covariate_rankit_df, covariate_log_cpm_df, covariate_df, covariate_log2_fc, cov_raw_ttest = get_covariate_and_log2_fold_df(metadata, genes, X_raw_counts[:, genes_indices], X_rankit[:, genes_indices], X_log_cpm[:, genes_indices], obs_soma_joinid2idx, covariate, genes_of_interest)\n",
    "\n",
    "                covariate_log2_fc['cell_type'] = cell_type + \", \" + tissue\n",
    "                if len(covariate_rankit_df) < 2:\n",
    "                    continue\n",
    "\n",
    "                covariate_log2_fc['gene_type'] = genes_type\n",
    "            \n",
    "                all_dfs.append(covariate_log2_fc)\n",
    "                covariate_raw_df = transform_covariate_df(covariate_raw_df, 'raw', covariate, cell_type, tissue)\n",
    "                covariate_rankit_df = transform_covariate_df(covariate_rankit_df, 'raw', covariate, cell_type, tissue)\n",
    "                covariate_log_cpm_df = transform_covariate_df(covariate_log_cpm_df, 'raw', covariate, cell_type, tissue)\n",
    "\n",
    "                all_covariate_dfs_raw.append(covariate_raw_df)\n",
    "                all_covariate_dfs_rankit.append(covariate_rankit_df)\n",
    "                all_covariate_dfs_log_cpm.append(covariate_log_cpm_df)\n",
    "        \n",
    "    log2_fold_df = pd.concat(all_dfs, axis= 0)\n",
    "    return log2_fold_df, all_covariate_dfs_rankit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4de1652b-4447-4daf-b637-0e18bb827298",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_figure(log2_fold_df, num_assays_arr, num_datasets_arr, max_pts = 300000):\n",
    "    \"\"\"\n",
    "    Generates plots of absolute log2fold change distribution between pairwise average gene expression values \n",
    "    stratified by covariates\n",
    "\n",
    "    :param log2_fold_df: datafrane containing log2_fold pairwise changes \n",
    "    :param num_assays_arr: array containing number of assays per cell_type\n",
    "    :param num_datasets_arr: array containing number of datasets per cell_type\n",
    "    :returns: nothing\n",
    "    \"\"\"\n",
    "    colors = [\"#b19fc9\", \"#88d5d4\", \"#f7cb6c\", \"#619c80\", \"#df7670\", \"#f3a5ac\"]\n",
    "    log2_fold_df['method'] = log2_fold_df['method'].apply(lambda x: 'quantile normalization' if x == 'rankit' else x)\n",
    "    \n",
    "    if len(log2_fold_df) > max_pts:   \n",
    "        log2_fold_df_sampled = log2_fold_df.sample(max_pts)\n",
    "    else:\n",
    "        log2_fold_df_sampled = log2_fold_df\n",
    "    fig = px.box(log2_fold_df_sampled, y=\"pairwise log2 fold change\", x = 'cell_type', facet_col = \"covariate\", color = \"method\", color_discrete_sequence = colors, category_orders={\"method\": [\"raw counts\", \"quantile normalization\", \"log CPM\"], \"cell_type\" : cell_types})\n",
    "\n",
    "    fig.update_layout(width=2000,height=1000, title_text=\"<b>Absolute log2Fold change distribution between pairwise average gene expression<br> values stratified by covariates</b><br><br>\", title_x=0.5, title_y = 0.98)\n",
    "\n",
    "    fig.add_hline(y=1, line_width=2, line_dash=\"dash\", line_color=\"gray\", annotation_text = \"log FC = 1\")\n",
    "    fig.update_traces(marker=dict(size=2))\n",
    "    for x, num_datasets, num_assays in zip(sorted_cell_types, num_datasets_arr, num_assays_arr):\n",
    "        fig.add_annotation(row=1,col=1, x=x, y=-0.3, text=\"N=\" + str(int(num_assays)), arrowhead=False, showarrow = False)\n",
    "        fig.add_annotation(row=1,col=2, x=x, y=-0.3, text=\"N=\" + str(int(num_datasets)), arrowhead=False, showarrow=False)\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "638d2d82-f2eb-4dbd-ad8e-8f725e807022",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3458 observations\n",
      "Parsing chunk Batch: 0\n",
      "\tCompute rankit values Batch: 0\n",
      "\tCompute log CPM values Batch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 dataset_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 assay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10791 observations\n",
      "Parsing chunk Batch: 0\n",
      "\tCompute rankit values Batch: 0\n",
      "\tCompute log CPM values Batch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing chunk Batch: 1\n",
      "\tCompute rankit values Batch: 1\n",
      "\tCompute log CPM values Batch: 1\n",
      "There are 4 dataset_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 assay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 29505 observations\n",
      "Parsing chunk Batch: 0\n",
      "\tCompute rankit values Batch: 0\n",
      "\tCompute log CPM values Batch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing chunk Batch: 1\n",
      "\tCompute rankit values Batch: 1\n",
      "\tCompute log CPM values Batch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing chunk Batch: 2\n",
      "\tCompute rankit values Batch: 2\n",
      "\tCompute log CPM values Batch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 dataset_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 assay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 23498 observations\n",
      "Parsing chunk Batch: 0\n",
      "\tCompute rankit values Batch: 0\n",
      "\tCompute log CPM values Batch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing chunk Batch: 1\n",
      "\tCompute rankit values Batch: 1\n",
      "\tCompute log CPM values Batch: 1\n",
      "Parsing chunk Batch: 2\n",
      "\tCompute rankit values Batch: 2\n",
      "\tCompute log CPM values Batch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 dataset_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 assay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11818 observations\n",
      "Parsing chunk Batch: 0\n",
      "\tCompute rankit values Batch: 0\n",
      "\tCompute log CPM values Batch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing chunk Batch: 1\n",
      "\tCompute rankit values Batch: 1\n",
      "\tCompute log CPM values Batch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 dataset_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 assay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60519 observations\n",
      "Parsing chunk Batch: 0\n",
      "\tCompute rankit values Batch: 0\n",
      "\tCompute log CPM values Batch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing chunk Batch: 1\n",
      "\tCompute rankit values Batch: 1\n",
      "\tCompute log CPM values Batch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing chunk Batch: 2\n",
      "\tCompute rankit values Batch: 2\n",
      "\tCompute log CPM values Batch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing chunk Batch: 3\n",
      "\tCompute rankit values Batch: 3\n",
      "\tCompute log CPM values Batch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing chunk Batch: 4\n",
      "\tCompute rankit values Batch: 4\n",
      "\tCompute log CPM values Batch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing chunk Batch: 5\n",
      "\tCompute rankit values Batch: 5\n",
      "\tCompute log CPM values Batch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing chunk Batch: 6\n",
      "\tCompute rankit values Batch: 6\n",
      "\tCompute log CPM values Batch: 6\n",
      "There are 13 dataset_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_covariate_df[col + \"_avg\"] = pair2mean[col]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_statistic\"] = pair2ttest[col][0]\n",
      "/var/folders/5x/7vqbx7g95jl3tg9t0h1_fp400000gq/T/ipykernel_1405/1998459185.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ttest_df[col + \"_p_value\"] = pair2ttest[col][1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 assay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Note that these cells were chosen because they were leaves in the ontology. See the code that was used under 'Choose cell type' section above\n",
    "cell_types = [('CD16-positive, CD56-dim natural killer cell, human', 'lung'), ('IgA plasma cell', 'small intestine'), ('central memory CD8-positive, alpha-beta T cell', 'blood'), ('enterocyte of colon', 'small intestine'), ('kidney loop of Henle thin ascending limb epithelial cell', 'kidney'), ('mucosal invariant T cell', 'blood'), ('naive thymus-derived CD8-positive, alpha-beta T cell', 'kidney'), ('plasmacytoid dendritic cell, human', 'blood'), ('type I pneumocyte', 'lung')]\n",
    "log2_fold_df, all_covariate_dfs_rankit = get_pairwise_stratified_log2_fold_changes(cell_types, covariates = ['dataset_id', 'assay'], all_genes = True)\n",
    "all_covariate_rankits = pd.concat(all_covariate_dfs_rankit)\n",
    "for cell, tissue in cell_types:\n",
    "    cell_name = cell + \", \" + tissue\n",
    "    cov_cell_df = all_covariate_rankits[all_covariate_rankits['cell_type'] == cell_name]\n",
    "\n",
    "    num_datasets = len(cov_cell_df[cov_cell_df['covariate'] == 'dataset_id']) - 1\n",
    "    num_assays = len(cov_cell_df[cov_cell_df['covariate'] == 'assay']) - 1\n",
    "\n",
    "    log2_fold_df.loc[(log2_fold_df['cell_type'] == cell_name), 'num_datasets'] = num_datasets\n",
    "    log2_fold_df.loc[(log2_fold_df['cell_type'] == cell_name), 'num_assays'] = num_assays\n",
    "\n",
    "log2_fold_df = log2_fold_df[['pairwise log2 fold change', 'method', 'covariate', 'cell_type', 'gene_name', 'ttest p_value', 'num_datasets', 'num_assays', 'mean']]\n",
    "\n",
    "# take absolute value\n",
    "log2_fold_df['pairwise log2 fold change'] = log2_fold_df['pairwise log2 fold change'].apply(lambda x: abs(x))\n",
    "log2_fold_df = log2_fold_df[(log2_fold_df['num_datasets'] > 1) & (log2_fold_df['num_assays'] > 1)]\n",
    "sorted_cell_types = sorted(log2_fold_df['cell_type'].unique())\n",
    "log2_fold_df = log2_fold_df.sort_values('cell_type').reset_index()\n",
    "num_assays_arr = [log2_fold_df[log2_fold_df['cell_type'] == c]['num_assays'].values[0] for c in sorted_cell_types]\n",
    "num_datasets_arr = [log2_fold_df[log2_fold_df['cell_type'] == c]['num_datasets'].values[0] for c in sorted_cell_types]\n",
    "\n",
    "\n",
    "log2_fold_sampled_df = sample_obs_per_cell_type(sorted_cell_types, log2_fold_df)\n",
    "generate_figure(log2_fold_sampled_df, num_assays_arr, num_datasets_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6168005f-86ce-459a-a82e-df19c7e3f8c3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Compute standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ad59466-8c0c-4870-983c-f588c9c2f9da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "log2_fold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1dee480-f155-4b29-a9ba-d36ed31e78ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "log2_fold_raw_counts_df = log2_fold_df[log2_fold_df['method'] == 'raw counts']\n",
    "log2_fold_rankit_df = log2_fold_df[log2_fold_df['method'] == 'rankit']\n",
    "log2_fold_log_cpm_df = log2_fold_df[log2_fold_df['method'] == 'ln (CPM + 1)']\n",
    "\n",
    "stds = []\n",
    "covariates = []\n",
    "methods = []\n",
    "cell_types_arr = []\n",
    "cell_types = log2_fold_df['cell_type'].unique()\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    for covariate in ['dataset_id', 'assay']:\n",
    "        log2_fold_raw_counts_covariate_ct = log2_fold_raw_counts_df[(log2_fold_raw_counts_df['covariate'] == covariate) & (log2_fold_raw_counts_df['cell_type'] == cell_type)]\n",
    "        log2_fold_rankit_covariate_ct = log2_fold_rankit_df[(log2_fold_rankit_df['covariate'] == covariate) & (log2_fold_rankit_df['cell_type'] == cell_type)]\n",
    "        log2_fold_log_cpm_covariate_ct = log2_fold_log_cpm_df[(log2_fold_log_cpm_df['covariate'] == covariate) & (log2_fold_log_cpm_df['cell_type'] == cell_type)]\n",
    "\n",
    "        n = len(log2_fold_raw_counts_covariate_ct)\n",
    "        n_total = len(log2_fold_raw_counts_df[log2_fold_raw_counts_df['covariate'] == covariate])\n",
    "        k = log2_fold_rankit_df['cell_type'].nunique()\n",
    "\n",
    "        std_covariate_raw = statistics.variance(log2_fold_raw_counts_covariate_ct['pairwise log2 fold change'].values) * ((n - 1) / (n_total - k))\n",
    "        std_covariate_rankit = statistics.variance(log2_fold_rankit_covariate_ct['pairwise log2 fold change'].values) * ((n - 1) / (n_total - k))\n",
    "        std_covariate_log_cpm = statistics.variance(log2_fold_log_cpm_covariate_ct['pairwise log2 fold change'].values) * ((n - 1) / (n_total - k))\n",
    "\n",
    "        stds.extend([std_covariate_raw, std_covariate_rankit, std_covariate_log_cpm])\n",
    "        covariates.extend([covariate] * 3)\n",
    "        cell_types_arr.extend([cell_type] * 3)\n",
    "        methods.extend(['raw counts', 'rankit', 'log CPM'])\n",
    "std_df = pd.DataFrame({'cell_type' : cell_types_arr, 'covariate' : covariates, 'method' : methods, 'std' : stds})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecf97201-3215-45ac-bb41-cffcf2453c87",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Average variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1121e9e9-292a-446a-8459-0ecca5cd3b34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "np.sqrt(std_df.groupby(['method', 'covariate']).sum())"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "log2_fold_change_analyses",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
